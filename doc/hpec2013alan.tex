\documentclass[conference]{IEEEtran}
%\hyphenation{op-tical net-works semi-conduc-tor}
%%%% Testing changes
\begin{document}
\title{Novel Algebras for Advanced Analytics in Julia}

\author{\IEEEauthorblockN{Jeremy Kepner\IEEEauthorrefmark{1},
Viral B. Shah\IEEEauthorrefmark{2},
Jeff Bezanson\IEEEauthorrefmark{3}, 
Stefan Karpinski\IEEEauthorrefmark{4} and
Alan Edelman\IEEEauthorrefmark{5}}
\IEEEauthorblockA{\IEEEauthorrefmark{1}Email: kepner@ll.mit.edu}
\IEEEauthorblockA{\IEEEauthorrefmark{2}Email: viral@mayin.org}
\IEEEauthorblockA{\IEEEauthorrefmark{3}Email: jeff.bezanson@gmail.com}
\IEEEauthorblockA{\IEEEauthorrefmark{4}Email: stefan@karpinski.org}
\IEEEauthorblockA{\IEEEauthorrefmark{5}Email: edelman@math.mit.edu}}

% make the title area
\maketitle

\begin{abstract}
%\boldmath
A linear algebraic
based approach to graph algorithms that exploits the sparse adjacency
matrix representation of graphs can provide a variety of
benefits. These benefits include syntactic simplicity, easier
implementation, and higher performance.  One way to employ linear
algebra techniques for graph algorithms is to use a broader definition
of matrix and vector multiplication.  We demonstrate through the use of the
Julia language system how easy it is to explore semirings using linear algebraic
methodologies.
\end{abstract}

\section{Introduction}

\subsection{Semiring algebra}

The duality between the canonical representation of graphs as abstract
collections of vertices and edges and a sparse adjacency matrix
representation has been a part of graph theory since its inception
~\cite{Konig1931}, ~\cite{Konig1936}. Matrix algebra has been
recognized as a useful tool in graph theory for nearly as long
(see~\cite{Harary1969} and references therein).  A linear algebraic
based approach to graph algorithms that exploits the sparse adjacency
matrix representation of graphs can provide a variety of
benefits. These benefits include syntactic simplicity, easier
implementation, and higher performance.  One way to employ linear
algebra techniques for graph algorithms is to use a broader definition
of matrix and vector multiplication. One such broader definition is
that of a semiring.  For example, in semiring notation we write
matrix-matrix multiply as:

$$C = A +.* B$$

where $$+.*$$ denotes standard matrix multiply.  In such notation, a
semiring requires that addition and multiplication are associative,
addition is commutative, and multiplication distributes over addition
from both left and right.  In graph algorithms, a fundamental
operation is matrix-matrix multiply where both matrices are sparse.
This operation represents multi source 1-hop breadth first search
(BFS) and combine, which is the foundation of many graph
algorithms~\cite{shahgilbert}.  In addition, it is often the case that
operations other than standard matrix multiply are desired, for
example:

\begin{enumerate}
\item $$C = A \ {\max.+} B$$
\item $$C = A \ \min.\max B$$
\item $$C = A \ |.\& B \ ({\mbox or.and})$$
\item $$C = A f().g() B $$
\end{enumerate}

With this more general case of sparse matrix multiply, a wide range of graphs algorithms can be implemented~\cite{KepnerGilbertBook}.

\section{Application example}

A classic example of the utility of the semiring approach is in
finding the minimum path between all vertices in graph (see
~\cite{Rader} in ~\cite{KepnerGilbertBook}.  Given a weighted
adjacency matrix for a graph where $A(i,j) = w_{ij}$ is the weight of
a directed edge from vertex $i$ to vertex $j$.  Let $C(i,j)_2$ be the
minimum 2-hop cost from vertex $i$ to vertex $j$ (if such a path
exists).  $C_2$ can be computed via the semiring matrix product:

$$C_2 = A \ \min.+ A$$

Likewise, $C_3$ can be computed via

$$C_3 = A\  \min.+ A \min.+ A$$

and more generally

$$C_k = A^k$$

\section{Julia}

Julia is emerging as a very popular computing technology for high performance
technical computing.  It has been designed from the ground up to take advantage
of modern techniques for executing dynamic languages efficiently, and still
be of appeal to scientists, engineers, data analysts, and other
practicitioners of technical computing\cite{julia}.

Despite advances in compiler technology and execution for
high-performance computing, programmers continue to prefer high-level
dynamic languages for algorithm development and data analysis in
applied math, engineering,  the sciences, and general data analysis. High-level environments
such as Matlab~\cite{matlab}, Octave~\cite{Octave}, R~\cite{Rlang},
SciPy~\cite{numpy}, and SciLab~\cite{scilab} provide greatly increased
convenience and productivity. However, C and Fortran remain the gold
standard languages for computationally-intensive problems because
high-level dynamic languages still lack sufficient performance. As a
result, the most challenging areas of technical computing have
benefited the least from the increased abstraction and productivity
offered by higher level languages.

Two-tiered architectures have emerged as the standard compromise between
convenience and performance: programmers express high-level logic in a
dynamic language while the heavy lifting is done in C and Fortran. The
aforementioned dynamic technical computing environments are all themselves
instances of this design. While this approach is effective for some
applications, there are drawbacks. It would be preferable to write
compute-intensive code in a more productive language as well. This is
particularly true when developing parallel algorithms, where code
complexity can increase dramatically. Instead, there is pressure to write
``vectorized'' code, which is unnatural for many problems and might
generate large temporary objects which could be avoided with explicit
loops. Programming in two languages is more complex than using either
language by itself due to the need for mediation between different type
domains and memory management schemes. Interfacing between layers may add
significant overhead and makes whole-program optimization difficult.
Two-tiered systems also present a social barrier, preventing most users
from understanding or contributing to their internals.

Julia is designed from the ground up to take advantage of modern
techniques for executing dynamic languages efficiently. As a result, Julia
has the performance of a statically compiled language while providing
interactive dynamic behavior and productivity like Python, LISP or Ruby.
The key ingredients of performance are:
\begin{itemize}
\item Rich type information, provided naturally by multiple dispatch;
\item Aggressive code specialization against run-time types;
\item JIT compilation using the LLVM compiler framework~\cite{LLVM}.
\end{itemize}
Although a sophisticated type system is made available to the programmer,
it remains unobtrusive in the sense that one is never required to specify
types. Type information flows naturally from having actual values (and
hence types) at the time of code generation, and from the language's core
paradigm: by expressing the behavior of functions using multiple dispatch,
the programmer unwittingly provides the compiler with extensive type
information.

We recommend trying the code examples in this paper.  Just a few moments may
convince the reader that Julia is simple yet powerful.
All of the code may be found on GITHUB:
\verb+github.com/ViralBShah/SemiringAlgebra.jl+



\section{Semiring algebra in Julia}

Julia's ordinary matrix multiplication is recognizable to users of many
high level languages: \\
{\tt A=rand(m,n); \\  B=rand(n,p); \\ C=A*B } \\ 
or one can equally well use the prefix notation \\
{\tt C = *(A,B)} \\ 
instead of the infix notation.

We believe that users of matrix-multiply who are use 
to such compact expressions would prefer not to have 
overly complicated syntax to express the more general 
semirings.  Julia offers two simple possibilities that are readily
available for exploration: 

1) Star overloading:
This method is recommended for interactive exploration of many semiring operators. 
Without introducing any types, define  {\tt *(f,g)(A,B)} to 
perform the semiring operation very generally, with no a-priori restriction
on the binary functions {\tt f} or {\tt g}.   Upon overloading the star operator,
and defining the ringmatmul, the following immediately work in Julia:
\begin{verbatim}
*(max,+)(A,B)  
*(min,max) (A,B)  
*(|,&) (A,B)  
*(+,*) (A,B)
\end{verbatim}  
The last example returns the same value as {\tt *(A,B)} or {\tt A*B}.

We note users can also equally well now type the infix notation,
{\tt (max * +)(A,B) } though users should avoid potentially ambiguous situations such as
{\tt (+ * *)}.

2) Creation of semiring objects:  This method is recommended for users who are working exclusively in one semiring and wish to optimize notation and performance.  In this method,
a semiring type is created.  One overloads scalar {\tt +} and scalar {\tt *} only,
and thanks to the care taken in Julia's abstractions,  automatically 
{\tt *(A,B)} or {\tt A*B} provides the semiring matrix multiply without any notational
hindrance.
   
\subsection{Star Overloading}

First time users should readily and effortlessly be able to google, download, and install Julia.
The star overloading functionality may be explored by typing directly into a Julia session:
\begin{verbatim}
function ringmatmul(pl,ti,A,B)
m=size(A,1); n=size(B,2); p=size(A,2)
C=[ti(A[i,1],B[1,j]) for i=1:m,j=1:n]
for i=1:m, j=1:n, k=2:p
   C[i,j]=pl(C[i,j],ti(A[i,k],B[k,j]))
end    
end      
   
function *(f::Function,g::Function)
   (A,B)->ringmatmul(f,g,A,B)
end
\end{verbatim}

We believe first time Julia users can readily understand the function {\tt ringmatmul}, which is mainly the usual matrix multiply loop.
The function takes four arguments, the first two, {\tt pl} and {\tt ti}, are functions that will play the role of plus and times.  Functions are first class variables in Julia and thus may be arguments to other functions.  The second two variables are the arrays {\tt A} and {\tt B}.
The function {\tt ringmatmul} is redefining matrix multiply in terms of {\tt pl} and {\tt ti}.

The second function overloads the symbol ``*", for the convenience of the user using the multiple dispatch mechanism.  It says that if ``*"  is called with two arguments, both of which have the type {\tt Function}, then the result is a function itself which takes two arrays as arguments, and proceeds to compute the semiring  {\tt ringmatmul} with arguments {\tt f,g,A,B}.


\subsection{Semiring Objects}

Here we create a ``multiply-plus'' semiring.  While this seems hardwired, one
can at time change the definitions of  ``+'' and ``*'' which below are set to 
max and plus.  The semiring does not need to be taught matrix multiply,
and will work on matrices of any type (e.g. ints, floats, ...) and will
also work on dense or sparse matrices.



\begin{verbatim}
immutable MPNumber{T} <: Number
    val::T
end

+(a::MPNumber,b::MPNumber)
      = MPNumber(max(a.val,b.val))
*(a::MPNumber,b::MPNumber)
      = MPNumber(a.val+b.val)
show(io::IO, k::MPNumber)
      = print(io, k.val)

zero{T}(::Type{MPNumber{T}})
      = MPNumber(typemin(T))
one{T}(::Type{MPNumber{T}})
      = MPNumber(zero(T))
promote_rule(::Type{MPNumber},::Type{Number}) 
      = MPNumber

mparray(A::Array) = map(MPNumber, A)
array{T}(A::Array{MPNumber{T}})
      = map(x->x.val, A)
mpsparse(S::SparseMatrixCSC)
      = SparseMatrixCSC(S.m, S.n, S.colptr, 
             S.rowval,mparray(S.nzval))
\end{verbatim}


The first function \verb+MPNumber+ is the constructor for a Max Plus Number.
Then plus and times are defined as max and plus respectively, followed by 
a routine IO function.

The zero and one in this semiring are defined as the identity elements for max and plus,
and the promote rule is a Julia construction which allows semi-ring numbers and ordinary
numbers to work together.

Finally the last three functions allow for the conversion between ordinary arrays and the semi-ring, with a special extra constructor for the important use case of sparse arrays.

Some examples of using the code:


\begin{verbatim}
A=mparray(rand(3,3)); B=mparray(rand(3,3));
A*B
A*A
A^2
C=mpsparse(sparse(eye(3,3)));
C*C
\end{verbatim}





\section{Performance}

The ultimate performance for an ordinary matrix multiply on floating point numbers 
would be the expected outcome of a highly tuned BLAS routine perhaps for a targeted
architecture.  The goal of Julia is to have the right combination of reasonable performance
for the machine and productivity for the human.  We have already demonstrated how expressive
Julia is.

On a Macbook Pro, we compared a dense BLAS run of matmul with an MPNumber{Float64} run in the semiring.
The BLAS time was 0.26msec (practically free!) for a 100x100 array.  The semiring time
was 313 msec.  This is no surprise.

More interesting and more useful is the comparison for sparse matrices.  For an n=100,000 by 100,000 sparse random array with density 1/n, the ordinary matrix multiply took 21 msec, and the semi-ring matrix multiply took a comperable
22 msec.

For a higher density (5/n) we found 461 msec for the matmul compared to 414 msec in the semi-ring.




\section{Conclusion}

Julia facilitates the implementation and exploration of graph algorithms through
the semiring notation of generalized matrix mutliply.  Thhese algorithms appear
in applications to data analysis and related fields.  Exploitation of sparse data 
strucutres provides simple easy implemeentations with reasonable performance.
Sparse semiring performance is likely to be comparable to ordinary sparse matmul in the Julia
language.


\bibliographystyle{plain}
\bibliography{hpec2013alan}

\end{document}
